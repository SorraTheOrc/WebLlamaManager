# Llama Manager Configuration
# Copy this file to .env and modify as needed

# API server port (serves the web UI)
API_PORT=3001

# Llama.cpp server port (OpenAI-compatible API)
LLAMA_PORT=8080

# Directory to store models
MODELS_DIR=~/models

# Maximum number of models loaded simultaneously
MODELS_MAX=2

# Default context size
CONTEXT_SIZE=8192

# Auto-start llama server when API starts
AUTO_START=true
